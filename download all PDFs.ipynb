{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber as pdfp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unneeded(item):\n",
    "    if '(' in item:\n",
    "        return item[:item.find('(')]\n",
    "    else:\n",
    "        return item\n",
    "    \n",
    "def make_list(pdf):\n",
    "    company_list = []\n",
    "    page_num = len(pdf.pages[:])\n",
    "    com = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)|Investment\\sLTM(.*)|\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "    for i in range(page_num):\n",
    "        if re.search(com,pdf.pages[i].extract_text()):\n",
    "            if pdf.pages[i].extract_text().split('\\n')[0][0].isdigit():\n",
    "                company_list.append('a_'+pdf.pages[i].extract_text().split('\\n')[0].replace(' ','_').replace(',','_'))\n",
    "            else:\n",
    "                company_list.append(pdf.pages[i].extract_text().split(\"\\n\")[0].replace(' ','_').replace(',','_'))\n",
    "    return company_list\n",
    "\n",
    "\n",
    "def make_df(pdf,company_name):\n",
    "    page_num = len(pdf.pages[:])\n",
    "    com = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)|Investment\\sLTM(.*)|\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "           \n",
    "\n",
    "    tt = company_name.split('\\n')\n",
    "    if tt[0] == '':\n",
    "        del tt[0]\n",
    "    first_value = re.compile(r\"(^\\D*[a-zA-Z\\s]\\(?\\d?\\)?)\\s\",re.DOTALL)\n",
    "    first_value_with_D = re.compile(r\"(^\\D*\\D\\(?\\d?\\)?)\\sDeal\",re.DOTALL)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i in tt:\n",
    "        try: \n",
    "    #print(re.search(second_value,i).group(1))\n",
    "    #print(re.findall(first_value,i))\n",
    "            if 'Deal' in re.search(first_value,i).group(1):\n",
    "                first = re.search(first_value_with_D,i).group(1)\n",
    "                second = i.strip(first).split()\n",
    "                in_df = pd.DataFrame(dict([(first,second)]),index = pd.Series(tt[0].split()).map(lambda x:str(x)).map(drop_unneeded))\n",
    "                df = pd.concat([df,in_df],axis=1)\n",
    "            elif 'NA' in re.findall(first_value,i)[0] or 'NM' in re.findall(first_value,i[1:])[0]:\n",
    "                first = re.search(first_value,i.replace('NA','0NA').replace('NM','0NA')).group(1)\n",
    "                second = i.strip(first).split()\n",
    "                in_df = pd.DataFrame(dict([(first,second)]),index = pd.Series(tt[0].split()).map(lambda x:str(x)).map(drop_unneeded))\n",
    "                df = pd.concat([df,in_df],axis=1)            \n",
    "            else:\n",
    "                first = re.search(first_value,i).group(1)\n",
    "                second = i.strip(first).split()\n",
    "                in_df = pd.DataFrame(dict([(first,second)]),index = pd.Series(tt[0].split()).map(lambda x:str(x)).map(drop_unneeded))\n",
    "                df = pd.concat([df,in_df],axis=1)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    df = df.replace('0NA','N/A')\n",
    "    lst = []\n",
    "    lstsi = []\n",
    "    for i in range(1,11):\n",
    "        lst.append('('+str(i)+')')\n",
    "        lstsi.append(str(i)+')')\n",
    "    for i in lst:\n",
    "        for j in lstsi:\n",
    "            try:\n",
    "                df.drop(i,axis=1,inplace = True)\n",
    "            except:\n",
    "                try:\n",
    "                    df.drop(j,axis=1,inplace = True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    return df\n",
    "\n",
    "def download_csv():\n",
    "    for name in os.listdir('./'):\n",
    "        if '.pdf' in name:\n",
    "            new_folder = './'+name[:-4]\n",
    "            if not os.path.exists(new_folder):\n",
    "                os.makedirs(new_folder)\n",
    "            pdf_path = './'+name\n",
    "            pdf = pdfp.open(pdf_path)\n",
    "            com1 = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)\",re.DOTALL)\n",
    "            com2 = re.compile(r\"Investment\\sLTM\\n(.*)\",re.DOTALL)\n",
    "            com3 = re.compile(r\"\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "            com4 = re.compile(r\"LTM\\n(\\d.*)\",re.DOTALL)\n",
    "            com5 = re.compile(r\"in\\s000s\\s(.*)\",re.DOTALL)\n",
    "            page_num = len(pdf.pages[:])\n",
    "            for i in range(page_num):\n",
    "                for j in [com1,com2,com3,com4,com5]:\n",
    "                    if re.search(j,pdf.pages[i].extract_text()):\n",
    "                        if pdf.pages[i].extract_text().split('\\n')[0][0].isdigit():\n",
    "                            locals()['a_'+pdf.pages[i].extract_text().split('\\n')[0].replace(' ','_')] = re.search(j,pdf.pages[i].extract_text()).group(1)\n",
    "                        else:\n",
    "                            locals()[pdf.pages[i].extract_text().split(\"\\n\")[0].replace(' ','_')] = re.search(j,pdf.pages[i].extract_text()).group(1)\n",
    "\n",
    "            for i in make_list(pdf):\n",
    "                try:\n",
    "                    make_df(pdf,eval(i)).to_csv(new_folder+'/%s.csv'%i)\n",
    "                except:\n",
    "                    continue\n",
    "download_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unneeded(item):\n",
    "    if '(' in item:\n",
    "        return item[:item.find('(')]\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "def make_list(pdf):\n",
    "    company_list = []\n",
    "    page_num = len(pdf.pages[:])\n",
    "    com = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)|Investment\\sLTM(.*)|\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "    for i in range(page_num):\n",
    "        if re.search(com,pdf.pages[i].extract_text()):\n",
    "            if pdf.pages[i].extract_text().split('\\n')[1][0].isdigit():\n",
    "                company_list.append('a_'+pdf.pages[i].extract_text().split('\\n')[1].replace(' ','_').replace(',','_'))\n",
    "            else:\n",
    "                company_list.append(pdf.pages[i].extract_text().split(\"\\n\")[1].replace(' ','_').replace(',','_'))\n",
    "    return company_list\n",
    "\n",
    "\n",
    "def make_df(pdf,company_name):\n",
    "    page_num = len(pdf.pages[:])\n",
    "    com = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)|Investment\\sLTM(.*)|\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "           \n",
    "\n",
    "    tt = company_name.split('\\n')\n",
    "    if tt[0] == '':\n",
    "        del tt[0]\n",
    "    first_value = re.compile(r\"(^\\D*\\w\\(?\\d?\\)?)\\s\")\n",
    "    second_value = re.compile(r\"^\\D*\\w\\(?\\d?\\)?\\s(.*)\")\n",
    "    first_value_with_D = re.compile(r\"(^\\D*\\D\\(?\\d?\\)?)\\sDeal\")\n",
    "    second_value_with_D = re.compile(r\"^\\D*\\D\\(?\\d?\\)?\\s(Deal.*)\")\n",
    "    df = pd.DataFrame()\n",
    "    for i in tt:\n",
    "        try: \n",
    "    #print(re.search(second_value,i).group(1))\n",
    "    #print(re.findall(first_value,i))\n",
    "            if 'Deal' in re.findall(first_value,i)[0]:\n",
    "                in_df = pd.DataFrame(dict([(re.findall(first_value_with_D,i)[0],re.search(second_value_with_D,i).group(1).split())]))\n",
    "                df = pd.concat([df,in_df],axis=1)\n",
    "            elif 'NA' in re.findall(first_value,i)[0] or 'NM' in re.findall(first_value,i)[0]:\n",
    "                in_df = pd.DataFrame(dict([(re.findall(first_value,i.replace('NA','0NA').replace('NM','0NA'))[0],re.search(second_value,i.replace('NA','0NA').replace('NM','0NA')).group(1).split())]))\n",
    "                df = pd.concat([df,in_df],axis=1)            \n",
    "            else:    \n",
    "                in_df = pd.DataFrame(dict([(re.findall(first_value,i)[0],re.search(second_value,i).group(1).split())]))\n",
    "                df = pd.concat([df,in_df],axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    df = df.dropna(thresh = len(df.columns)*0.6)\n",
    "    df = df.dropna(thresh = len(df)*0.5,axis=1)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    df = df.replace('0NA','N/A')\n",
    "    lst = []\n",
    "    lstsi = []\n",
    "    for i in range(1,11):\n",
    "        lst.append('('+str(i)+')')\n",
    "        lstsi.append(str(i)+')')\n",
    "    for i in range(len(lst)):\n",
    "        try:\n",
    "            df.drop(lst[i],axis=1,inplace = True)\n",
    "        except:\n",
    "            try:\n",
    "                df.drop(lstsi[i],axis = 1, inplace = True)\n",
    "            except:\n",
    "                continue\n",
    "          \n",
    "\n",
    "    return df\n",
    "\n",
    "def download_csv():\n",
    "    for name in os.listdir('./'):\n",
    "        if '.pdf' in name:\n",
    "            new_folder = './'+name[:-4]\n",
    "            os.makedirs(new_folder)\n",
    "            pdf_path = './'+name\n",
    "            pdf = pdfp.open(pdf_path)\n",
    "            com = re.compile(r\"[LTM\\n]?\\(\\$Ms\\)(.*)|Investment\\sLTM(.*)|\\(?\\$\\sin\\s[mM]illions\\)?\\s(.*)\",re.DOTALL)\n",
    "            page_num = len(pdf.pages[:])\n",
    "            for i in range(page_num):\n",
    "                    if re.search(com,pdf.pages[i].extract_text()):\n",
    "                        if pdf.pages[i].extract_text().split('\\n')[1][0].isdigit():\n",
    "                            locals()['a_'+pdf.pages[i].extract_text().split('\\n')[1].replace(' ','_')] = re.search(com,pdf.pages[i].extract_text()).group()\n",
    "                        else:\n",
    "                            locals()[pdf.pages[i].extract_text().split(\"\\n\")[1].replace(' ','_')] = re.search(com,pdf.pages[i].extract_text()).group()\n",
    "            for i in make_list(pdf):\n",
    "                try:\n",
    "                    make_df(pdf,eval(i)).to_csv(new_folder+'/%s.csv'%i)\n",
    "                except:\n",
    "                    continue\n",
    "download_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
